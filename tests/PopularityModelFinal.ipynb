{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\Dimitrideboer\\OneDrive - Emixa\\Documents\\XRAYxEmixaHackathon\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Path to the desired directory\n",
    "desired_directory = r'c:\\Users\\Dimitrideboer\\OneDrive - Emixa\\Documents\\XRAYxEmixaHackathon'\n",
    "\n",
    "# Set the current working directory to the desired directory\n",
    "os.chdir(desired_directory)\n",
    "\n",
    "# Print the current working directory to confirm\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2571\n",
      "[LightGBM] [Info] Number of data points in the train set: 5820, number of used features: 213\n",
      "[LightGBM] [Info] Start training from score 2.169931\n",
      "Overall Metrics:\n",
      "Mean Squared Error: 1.0808254360928276\n",
      "Mean Absolute Error: 0.7960561061347275\n",
      "R2 Score: 0.13332638841649025\n",
      "Root Mean Squared Error: 1.0396275468131977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DimitrideBoer\\OneDrive - Emixa\\Documents\\XRAYxEmixaHackathon\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from lightgbm import LGBMRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/PopularitySystem.csv')\n",
    "\n",
    "# Identify the columns\n",
    "target_columns = ['total_companies_bidded']\n",
    "feature_columns = df.columns.difference(target_columns).drop('total_bids')\n",
    "\n",
    "# Separate features and target variables\n",
    "X = df[feature_columns]\n",
    "y = df[target_columns]\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "numerical_cols = X.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "\n",
    "# # Preprocessing for numerical data\n",
    "# numerical_transformer = StandardScaler()\n",
    "\n",
    "# # Preprocessing for categorical data\n",
    "# categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# # Bundle preprocessing for numerical and categorical data\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', numerical_transformer, numerical_cols),\n",
    "#         ('cat', categorical_transformer, categorical_cols)\n",
    "#     ])\n",
    "\n",
    "# Preprocessing for numerical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing for categorical features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    #('imputer', SimpleImputer(strategy='constant', fill_value='most frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Define preprocessing for boolean features\n",
    "boolean_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "    # No need for additional transformation; booleans are already binary\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps for numerical and categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)# + boolean_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "x = preprocessor.fit_transform(X)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = LGBMRegressor(num_leaves=31, learning_rate=0.1, n_estimators=100)\n",
    "\n",
    "# Create the pipeline\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('regressor', model)])\n",
    "\n",
    "# # Hyperparameter tuning\n",
    "# param_grid = {\n",
    "#     'regressor__estimator__num_leaves': [31],\n",
    "#     'regressor__estimator__learning_rate': [0.1],\n",
    "#     'regressor__estimator__n_estimators': [100]\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(clf, param_grid, cv=2, scoring='neg_mean_squared_error', n_jobs=-1, verbose=3)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Best model\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "# Train the best model on the training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Calculate overall metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)  # Calculate RMSE\n",
    "\n",
    "print(\"Overall Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R2 Score:\", r2)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batterycapacity</th>\n",
       "      <th>bodytype</th>\n",
       "      <th>bpmvalue</th>\n",
       "      <th>cardistancevalue</th>\n",
       "      <th>cartypename</th>\n",
       "      <th>catalogincludingvalue</th>\n",
       "      <th>catalogvalue</th>\n",
       "      <th>costsvalue</th>\n",
       "      <th>duedateapk</th>\n",
       "      <th>enginehorsepower</th>\n",
       "      <th>...</th>\n",
       "      <th>hasdamage</th>\n",
       "      <th>isimportcar</th>\n",
       "      <th>minbid</th>\n",
       "      <th>modelnameshort</th>\n",
       "      <th>remainingbpmvalue</th>\n",
       "      <th>taxliabilitypercentage</th>\n",
       "      <th>transmissiontype</th>\n",
       "      <th>vatmargin</th>\n",
       "      <th>vehicletype</th>\n",
       "      <th>xrayvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3057</th>\n",
       "      <td>33 kWh</td>\n",
       "      <td>Hatchb. 3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35818.0</td>\n",
       "      <td>Basic 33 kWh</td>\n",
       "      <td>33767.0</td>\n",
       "      <td>33767.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-03-20 00:00:00.000</td>\n",
       "      <td>184.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>11937.0</td>\n",
       "      <td>Mini Electric</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8 %</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>BTW</td>\n",
       "      <td>Personenauto</td>\n",
       "      <td>14044.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     batterycapacity   bodytype  bpmvalue  cardistancevalue   cartypename  \\\n",
       "3057          33 kWh  Hatchb. 3       0.0           35818.0  Basic 33 kWh   \n",
       "\n",
       "      catalogincludingvalue  catalogvalue  costsvalue  \\\n",
       "3057                33767.0       33767.0         0.0   \n",
       "\n",
       "                   duedateapk  enginehorsepower  ...  hasdamage isimportcar  \\\n",
       "3057  2024-03-20 00:00:00.000             184.0  ...       True       False   \n",
       "\n",
       "       minbid  modelnameshort  remainingbpmvalue  taxliabilitypercentage  \\\n",
       "3057  11937.0   Mini Electric                0.0                     8 %   \n",
       "\n",
       "      transmissiontype vatmargin   vehicletype xrayvalue  \n",
       "3057         Automatic       BTW  Personenauto   14044.0  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bpmvalue': 3057    0.0\n",
       " Name: bpmvalue, dtype: float32,\n",
       " 'cardistancevalue': 3057    35818.0\n",
       " Name: cardistancevalue, dtype: float32,\n",
       " 'catalogincludingvalue': 3057    33767.0\n",
       " Name: catalogincludingvalue, dtype: float32,\n",
       " 'catalogvalue': 3057    33767.0\n",
       " Name: catalogvalue, dtype: float32,\n",
       " 'costsvalue': 3057    0.0\n",
       " Name: costsvalue, dtype: float32,\n",
       " 'enginehorsepower': 3057    184.0\n",
       " Name: enginehorsepower, dtype: float32,\n",
       " 'equipmentvalue': 3057    0.0\n",
       " Name: equipmentvalue, dtype: float32,\n",
       " 'minbid': 3057    11937.0\n",
       " Name: minbid, dtype: float32,\n",
       " 'remainingbpmvalue': 3057    0.0\n",
       " Name: remainingbpmvalue, dtype: float32,\n",
       " 'xrayvalue': 3057    14044.0\n",
       " Name: xrayvalue, dtype: float32,\n",
       " 'batterycapacity': 3057    33 kWh\n",
       " Name: batterycapacity, dtype: object,\n",
       " 'bodytype': 3057    Hatchb. 3\n",
       " Name: bodytype, dtype: object,\n",
       " 'cartypename': 3057    Basic 33 kWh\n",
       " Name: cartypename, dtype: object,\n",
       " 'duedateapk': 3057    2024-03-20 00:00:00.000\n",
       " Name: duedateapk, dtype: object,\n",
       " 'fueltype': 3057    Elektrisch\n",
       " Name: fueltype, dtype: object,\n",
       " 'hascosts': 3057    True\n",
       " Name: hascosts, dtype: object,\n",
       " 'hascostsmanual': 3057    False\n",
       " Name: hascostsmanual, dtype: object,\n",
       " 'hasdamage': 3057    True\n",
       " Name: hasdamage, dtype: object,\n",
       " 'isimportcar': 3057    False\n",
       " Name: isimportcar, dtype: object,\n",
       " 'modelnameshort': 3057    Mini Electric\n",
       " Name: modelnameshort, dtype: object,\n",
       " 'taxliabilitypercentage': 3057    8 %\n",
       " Name: taxliabilitypercentage, dtype: object,\n",
       " 'transmissiontype': 3057    Automatic\n",
       " Name: transmissiontype, dtype: object,\n",
       " 'vatmargin': 3057    BTW\n",
       " Name: vatmargin, dtype: object,\n",
       " 'vehicletype': 3057    Personenauto\n",
       " Name: vehicletype, dtype: object}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 0-dimensional, but 1 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 32\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Convert the sample input to match the initial types\u001b[39;00m\n\u001b[0;32m      5\u001b[0m sample_input_converted \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbpmvalue\u001b[39m\u001b[38;5;124m'\u001b[39m: sample_input[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbpmvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcardistancevalue\u001b[39m\u001b[38;5;124m'\u001b[39m: sample_input[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcardistancevalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvehicletype\u001b[39m\u001b[38;5;124m'\u001b[39m: sample_input[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvehicletype\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m     30\u001b[0m }\n\u001b[1;32m---> 32\u001b[0m onnx_model \u001b[38;5;241m=\u001b[39m \u001b[43mto_onnx\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_input_converted\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use a sample of the training data for conversion\u001b[39;49;00m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_opset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m14\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mai.onnx.ml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Save the ONNX model to a file\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipeline_lightgbm.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\Users\\DimitrideBoer\\OneDrive - Emixa\\Documents\\XRAYxEmixaHackathon\\venv\\Lib\\site-packages\\skl2onnx\\convert.py:260\u001b[0m, in \u001b[0;36mto_onnx\u001b[1;34m(model, X, name, initial_types, target_opset, options, white_op, black_op, final_types, dtype, naming, verbose)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    259\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mONNX(\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m--> 260\u001b[0m initial_types \u001b[38;5;241m=\u001b[39m \u001b[43mguess_initial_types\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_types\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[to_onnx] initial_types=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m initial_types)\n",
      "File \u001b[1;32mc:\\Users\\DimitrideBoer\\OneDrive - Emixa\\Documents\\XRAYxEmixaHackathon\\venv\\Lib\\site-packages\\skl2onnx\\algebra\\type_helper.py:85\u001b[0m, in \u001b[0;36mguess_initial_types\u001b[1;34m(X, initial_types)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initial_types \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m---> 85\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     86\u001b[0m         gt \u001b[38;5;241m=\u001b[39m _guess_type(X)\n\u001b[0;32m     87\u001b[0m         initial_types \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m, gt)]\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 0-dimensional, but 1 were indexed"
     ]
    }
   ],
   "source": [
    "# Prepare a sample input for ONNX conversion\n",
    "sample_input = X_train[:1]\n",
    "\n",
    "# Convert the sample input to match the initial types\n",
    "sample_input_converted = {\n",
    "    'bpmvalue': sample_input['bpmvalue'].astype(np.float32),\n",
    "    'cardistancevalue': sample_input['cardistancevalue'].astype(np.float32),\n",
    "    'catalogincludingvalue': sample_input['catalogincludingvalue'].astype(np.float32),\n",
    "    'catalogvalue': sample_input['catalogvalue'].astype(np.float32),\n",
    "    'costsvalue': sample_input['costsvalue'].astype(np.float32),\n",
    "    'enginehorsepower': sample_input['enginehorsepower'].astype(np.float32),\n",
    "    'equipmentvalue': sample_input['equipmentvalue'].astype(np.float32),\n",
    "    'minbid': sample_input['minbid'].astype(np.float32),\n",
    "    'remainingbpmvalue': sample_input['remainingbpmvalue'].astype(np.float32),\n",
    "    'xrayvalue': sample_input['xrayvalue'].astype(np.float32),\n",
    "    'batterycapacity': sample_input['batterycapacity'].astype(str),\n",
    "    'bodytype': sample_input['bodytype'].astype(str),\n",
    "    'cartypename': sample_input['cartypename'].astype(str),\n",
    "    'duedateapk': sample_input['duedateapk'].astype(str),\n",
    "    'fueltype': sample_input['fueltype'].astype(str),\n",
    "    'hascosts': sample_input['hascosts'].astype(str),\n",
    "    'hascostsmanual': sample_input['hascostsmanual'].astype(str),\n",
    "    'hasdamage': sample_input['hasdamage'].astype(str),\n",
    "    'isimportcar': sample_input['isimportcar'].astype(str),\n",
    "    'modelnameshort': sample_input['modelnameshort'].astype(str),\n",
    "    'taxliabilitypercentage': sample_input['taxliabilitypercentage'].astype(str),\n",
    "    'transmissiontype': sample_input['transmissiontype'].astype(str),\n",
    "    'vatmargin': sample_input['vatmargin'].astype(str),\n",
    "    'vehicletype': sample_input['vehicletype'].astype(str)\n",
    "}\n",
    "\n",
    "onnx_model = to_onnx(\n",
    "    clf,\n",
    "    np.array(sample_input_converted),  # Use a sample of the training data for conversion\n",
    "    target_opset={\"\": 14, \"ai.onnx.ml\": 2}\n",
    ")\n",
    "\n",
    "# Save the ONNX model to a file\n",
    "with open(\"pipeline_lightgbm.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingShapeCalculator",
     "evalue": "Unable to find a shape calculator for type '<class 'lightgbm.sklearn.LGBMRegressor'>'.\nIt usually means the pipeline being converted contains a\ntransformer or a predictor with no corresponding converter\nimplemented in sklearn-onnx. If the converted is implemented\nin another library, you need to register\nthe converted so that it can be used by sklearn-onnx (function\nupdate_registered_converter). If the model is not yet covered\nby sklearn-onnx, you may raise an issue to\nhttps://github.com/onnx/sklearn-onnx/issues\nto get the converter implemented or even contribute to the\nproject. If the model is a custom model, a new converter must\nbe implemented. Examples can be found in the gallery.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMissingShapeCalculator\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 35\u001b[0m\n\u001b[0;32m      7\u001b[0m initial_type \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbpmvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, FloatTensorType([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m])),\n\u001b[0;32m      8\u001b[0m                 (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcardistancevalue\u001b[39m\u001b[38;5;124m'\u001b[39m, FloatTensorType([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m])),\n\u001b[0;32m      9\u001b[0m                 (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcatalogincludingvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, FloatTensorType([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m])),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m                 (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxrayvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, StringTensorType([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m     33\u001b[0m                 ]\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Convert the model to ONNX\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m onnx_model \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_sklearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_opset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mai.onnx.ml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m#onnx_model = convert_sklearn(clf, initial_types=initial_type)#, target_opset=12)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Save the ONNX model to a file\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_model.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\Users\\DimitrideBoer\\OneDrive - Emixa\\Documents\\XRAYxEmixaHackathon\\venv\\Lib\\site-packages\\skl2onnx\\convert.py:184\u001b[0m, in \u001b[0;36mconvert_sklearn\u001b[1;34m(model, name, initial_types, doc_string, target_opset, custom_conversion_functions, custom_shape_calculators, custom_parsers, options, intermediate, white_op, black_op, final_types, dtype, naming, verbose)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[convert_sklearn] convert_topology\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 184\u001b[0m onnx_model \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_topology\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtopology\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_opset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremove_identity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mintermediate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[convert_sklearn] end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\DimitrideBoer\\OneDrive - Emixa\\Documents\\XRAYxEmixaHackathon\\venv\\Lib\\site-packages\\skl2onnx\\common\\_topology.py:1421\u001b[0m, in \u001b[0;36mconvert_topology\u001b[1;34m(topology, model_name, doc_string, target_opset, channel_first_inputs, options, remove_identity, verbose)\u001b[0m\n\u001b[0;32m   1412\u001b[0m container \u001b[38;5;241m=\u001b[39m ModelComponentContainer(\n\u001b[0;32m   1413\u001b[0m     target_opset, options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1414\u001b[0m     registered_models\u001b[38;5;241m=\u001b[39mtopology\u001b[38;5;241m.\u001b[39mregistered_models,\n\u001b[0;32m   1415\u001b[0m     white_op\u001b[38;5;241m=\u001b[39mtopology\u001b[38;5;241m.\u001b[39mraw_model\u001b[38;5;241m.\u001b[39m_white_op,\n\u001b[0;32m   1416\u001b[0m     black_op\u001b[38;5;241m=\u001b[39mtopology\u001b[38;5;241m.\u001b[39mraw_model\u001b[38;5;241m.\u001b[39m_black_op,\n\u001b[0;32m   1417\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m   1419\u001b[0m \u001b[38;5;66;03m# Traverse the graph from roots to leaves\u001b[39;00m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;66;03m# This loop could eventually be parallelized.\u001b[39;00m\n\u001b[1;32m-> 1421\u001b[0m \u001b[43mtopology\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_operators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1422\u001b[0m container\u001b[38;5;241m.\u001b[39mensure_topological_order()\n\u001b[0;32m   1424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(container\u001b[38;5;241m.\u001b[39minputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\DimitrideBoer\\OneDrive - Emixa\\Documents\\XRAYxEmixaHackathon\\venv\\Lib\\site-packages\\skl2onnx\\common\\_topology.py:1255\u001b[0m, in \u001b[0;36mTopology.convert_operators\u001b[1;34m(self, container, verbose)\u001b[0m\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;129;01min\u001b[39;00m operator\u001b[38;5;241m.\u001b[39moutputs:\n\u001b[0;32m   1253\u001b[0m     _check_variable_out_(variable, operator)\n\u001b[1;32m-> 1255\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_shape_calculator\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_converter(operator, container, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;66;03m# If an operator contains a sequence of operators,\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;66;03m# output variables are not necessarily known at this stage.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DimitrideBoer\\OneDrive - Emixa\\Documents\\XRAYxEmixaHackathon\\venv\\Lib\\site-packages\\skl2onnx\\common\\_topology.py:1091\u001b[0m, in \u001b[0;36mTopology.call_shape_calculator\u001b[1;34m(self, operator)\u001b[0m\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1090\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[Shape2] call infer_types for \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m, operator)\n\u001b[1;32m-> 1091\u001b[0m     \u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_types\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DimitrideBoer\\OneDrive - Emixa\\Documents\\XRAYxEmixaHackathon\\venv\\Lib\\site-packages\\skl2onnx\\common\\_topology.py:589\u001b[0m, in \u001b[0;36mOperator.infer_types\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer_types\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;66;03m# Invoke a core inference function\u001b[39;00m\n\u001b[0;32m    588\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 589\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MissingShapeCalculator(\n\u001b[0;32m    590\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to find a shape calculator for type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    591\u001b[0m                 \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_operator)))\n\u001b[0;32m    592\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    593\u001b[0m         shape_calc \u001b[38;5;241m=\u001b[39m _registration\u001b[38;5;241m.\u001b[39mget_shape_calculator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype)\n",
      "\u001b[1;31mMissingShapeCalculator\u001b[0m: Unable to find a shape calculator for type '<class 'lightgbm.sklearn.LGBMRegressor'>'.\nIt usually means the pipeline being converted contains a\ntransformer or a predictor with no corresponding converter\nimplemented in sklearn-onnx. If the converted is implemented\nin another library, you need to register\nthe converted so that it can be used by sklearn-onnx (function\nupdate_registered_converter). If the model is not yet covered\nby sklearn-onnx, you may raise an issue to\nhttps://github.com/onnx/sklearn-onnx/issues\nto get the converter implemented or even contribute to the\nproject. If the model is a custom model, a new converter must\nbe implemented. Examples can be found in the gallery.\n"
     ]
    }
   ],
   "source": [
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType, StringTensorType\n",
    "from skl2onnx import to_onnx\n",
    "\n",
    "# Convert the model to ONNX\n",
    "initial_type = [('float_input', FloatTensorType([None, len(feature_columns)]))]\n",
    "initial_type = [('bpmvalue', FloatTensorType([1, 1])),\n",
    "                ('cardistancevalue', FloatTensorType([1, 1])),\n",
    "                ('catalogincludingvalue', FloatTensorType([1, 1])),\n",
    "                ('catalogvalue', FloatTensorType([1, 1])),\n",
    "                ('costsvalue', FloatTensorType([1, 1])),\n",
    "                ('enginehorsepower', FloatTensorType([1, 1])),\n",
    "                ('equipmentvalue', FloatTensorType([1, 1])),\n",
    "                ('minbid', FloatTensorType([1, 1])),\n",
    "                ('remainingbpmvalue', FloatTensorType([1, 1])),\n",
    "                ('xrayvalue', FloatTensorType([1, 1])),\n",
    "                ('batterycapacity', StringTensorType([1, 1])),\n",
    "                ('bodytype', StringTensorType([1, 1])),\n",
    "                ('cartypename', StringTensorType([1, 1])),\n",
    "                ('duedateapk', StringTensorType([1, 1])),\n",
    "                ('fueltype', StringTensorType([1, 1])),\n",
    "                ('duedateapk', StringTensorType([1, 1])),\n",
    "                ('hascosts', StringTensorType([1, 1])),\n",
    "                ('hascostsmanual', StringTensorType([1, 1])),\n",
    "                ('hasdamage', StringTensorType([1, 1])),\n",
    "                ('isimportcar', StringTensorType([1, 1])),\n",
    "                ('modelnameshort', StringTensorType([1, 1])),\n",
    "                ('taxliabilitypercentage', StringTensorType([1, 1])),\n",
    "                ('transmissiontype', StringTensorType([1, 1])),\n",
    "                ('vatmargin', StringTensorType([1, 1])),\n",
    "                ('vehicletype', StringTensorType([1, 1])),\n",
    "                ('xrayvalue', StringTensorType([1, 1]))\n",
    "                ]\n",
    "# Convert the model to ONNX\n",
    "onnx_model = convert_sklearn(\n",
    "    clf,\n",
    "    initial_types=initial_type,\n",
    "    target_opset={\"\": 12, \"ai.onnx.ml\": 2},\n",
    ")\n",
    "#onnx_model = convert_sklearn(clf, initial_types=initial_type)#, target_opset=12)\n",
    "\n",
    "# Save the ONNX model to a file\n",
    "with open(\"best_model.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = X_train[:1]\n",
    "\n",
    "# Convert the sample input to a NumPy array\n",
    "sample_input_np = np.array([list(sample_input[col]) for col in sample_input.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['33 kWh'],\n",
       "       ['Hatchb. 3'],\n",
       "       ['0.0'],\n",
       "       ['35818.0'],\n",
       "       ['Basic 33 kWh'],\n",
       "       ['33767.0'],\n",
       "       ['33767.0'],\n",
       "       ['0.0'],\n",
       "       ['2024-03-20 00:00:00.000'],\n",
       "       ['184.0'],\n",
       "       ['0.0'],\n",
       "       ['Elektrisch'],\n",
       "       ['True'],\n",
       "       ['False'],\n",
       "       ['True'],\n",
       "       ['False'],\n",
       "       ['11937.0'],\n",
       "       ['Mini Electric'],\n",
       "       ['0.0'],\n",
       "       ['8 %'],\n",
       "       ['Automatic'],\n",
       "       ['BTW'],\n",
       "       ['Personenauto'],\n",
       "       ['14044.0']], dtype='<U32')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PopularityModel.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the best model to a file\n",
    "joblib.dump(best_model, 'PopularityModel.pkl')\n",
    "\n",
    "# To load the model from a file\n",
    "# loaded_model = joblib.load('best_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.18.0-cp311-cp311-win_amd64.whl.metadata (4.4 kB)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Requirement already satisfied: numpy>=1.24.2 in c:\\users\\dimitrideboer\\onedrive - emixa\\documents\\xrayxemixahackathon\\venv\\lib\\site-packages (from onnxruntime) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\dimitrideboer\\onedrive - emixa\\documents\\xrayxemixahackathon\\venv\\lib\\site-packages (from onnxruntime) (24.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\dimitrideboer\\onedrive - emixa\\documents\\xrayxemixahackathon\\venv\\lib\\site-packages (from onnxruntime) (3.20.2)\n",
      "Collecting sympy (from onnxruntime)\n",
      "  Downloading sympy-1.12.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting mpmath<1.4.0,>=1.1.0 (from sympy->onnxruntime)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime)\n",
      "  Downloading pyreadline3-3.4.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Downloading onnxruntime-1.18.0-cp311-cp311-win_amd64.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/5.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.6/5.6 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.8/5.6 MB 16.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 2.7/5.6 MB 16.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 3.6/5.6 MB 17.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.8/5.6 MB 19.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.6/5.6 MB 21.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.6/5.6 MB 17.9 MB/s eta 0:00:00\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "   ---------------------------------------- 0.0/46.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 46.0/46.0 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading sympy-1.12.1-py3-none-any.whl (5.7 MB)\n",
      "   ---------------------------------------- 0.0/5.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.0/5.7 MB 21.1 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 2.2/5.7 MB 27.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.3/5.7 MB 26.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.7/5.7 MB 25.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.7/5.7 MB 26.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.7/5.7 MB 26.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.7/5.7 MB 20.4 MB/s eta 0:00:00\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "   ---------------------------------------- 0.0/86.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 86.8/86.8 kB 5.1 MB/s eta 0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.2/536.2 kB 32.9 MB/s eta 0:00:00\n",
      "Downloading pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "   ---------------------------------------- 0.0/95.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 95.2/95.2 kB 2.7 MB/s eta 0:00:00\n",
      "Installing collected packages: pyreadline3, mpmath, flatbuffers, sympy, humanfriendly, coloredlogs, onnxruntime\n",
      "Successfully installed coloredlogs-15.0.1 flatbuffers-24.3.25 humanfriendly-10.0 mpmath-1.3.0 onnxruntime-1.18.0 pyreadline3-3.4.1 sympy-1.12.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DimitrideBoer\\OneDrive - Emixa\\Documents\\XRAYxEmixaHackathon\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2571\n",
      "[LightGBM] [Info] Number of data points in the train set: 5820, number of used features: 213\n",
      "[LightGBM] [Info] Start training from score 2.169931\n",
      "Overall Metrics:\n",
      "Mean Squared Error: 1.0808254360928276\n",
      "Mean Absolute Error: 0.7960561061347275\n",
      "R2 Score: 0.13332638841649025\n",
      "Root Mean Squared Error: 1.0396275468131977\n",
      "Model has been converted to ONNX and saved as 'pipeline_lightgbm.onnx'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from lightgbm import LGBMRegressor\n",
    "from skl2onnx import to_onnx, update_registered_converter\n",
    "from skl2onnx.common.data_types import FloatTensorType, StringTensorType\n",
    "from skl2onnx.common.shape_calculator import calculate_linear_regressor_output_shapes\n",
    "from onnxmltools.convert.lightgbm.operator_converters.LightGbm import convert_lightgbm\n",
    "import packaging.version as pv\n",
    "import onnxruntime as rt\n",
    "import warnings\n",
    "\n",
    "# Function to convert LightGBM model\n",
    "def skl2onnx_convert_lightgbm(scope, operator, container):\n",
    "    options = scope.get_options(operator.raw_operator)\n",
    "    if \"split\" in options:\n",
    "        if pv.Version(onnxmltools.__version__) < pv.Version(\"1.9.2\"):\n",
    "            warnings.warn(\n",
    "                \"Option split was released in version 1.9.2 but %s is \"\n",
    "                \"installed. It will be ignored.\" % onnxmltools.__version__\n",
    "            )\n",
    "        operator.split = options[\"split\"]\n",
    "    else:\n",
    "        operator.split = None\n",
    "    convert_lightgbm(scope, operator, container)\n",
    "\n",
    "# Register the converter for LGBMRegressor\n",
    "update_registered_converter(\n",
    "    LGBMRegressor,\n",
    "    \"LightGbmLGBMRegressor\",\n",
    "    calculate_linear_regressor_output_shapes,\n",
    "    skl2onnx_convert_lightgbm,\n",
    "    options={\"split\": None},\n",
    ")\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/PopularitySystem.csv')\n",
    "\n",
    "# Identify the columns\n",
    "target_columns = ['total_companies_bidded']\n",
    "feature_columns = df.columns.difference(target_columns).drop('total_bids')\n",
    "\n",
    "# Separate features and target variables\n",
    "X = df[feature_columns]\n",
    "y = df[target_columns]\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "numerical_cols = X.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Define the model\n",
    "model = LGBMRegressor()\n",
    "\n",
    "# Create the pipeline\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('regressor', model)])\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'regressor__num_leaves': [31],\n",
    "    'regressor__learning_rate': [0.1],\n",
    "    'regressor__n_estimators': [100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=2, scoring='neg_mean_squared_error', n_jobs=-1, verbose=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Calculate overall metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)  # Calculate RMSE\n",
    "\n",
    "print(\"Overall Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R2 Score:\", r2)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "\n",
    "# Prepare a sample input for ONNX conversion\n",
    "# Prepare a sample input for ONNX conversion\n",
    "sample_input = X_train[:1]\n",
    "\n",
    "# Convert the sample input to match the initial types\n",
    "sample_input_converted = {\n",
    "    'bpmvalue': sample_input['bpmvalue'].astype(np.float32),\n",
    "    'cardistancevalue': sample_input['cardistancevalue'].astype(np.float32),\n",
    "    'catalogincludingvalue': sample_input['catalogincludingvalue'].astype(np.float32),\n",
    "    'catalogvalue': sample_input['catalogvalue'].astype(np.float32),\n",
    "    'costsvalue': sample_input['costsvalue'].astype(np.float32),\n",
    "    'enginehorsepower': sample_input['enginehorsepower'].astype(np.float32),\n",
    "    'equipmentvalue': sample_input['equipmentvalue'].astype(np.float32),\n",
    "    'minbid': sample_input['minbid'].astype(np.float32),\n",
    "    'remainingbpmvalue': sample_input['remainingbpmvalue'].astype(np.float32),\n",
    "    'xrayvalue': sample_input['xrayvalue'].astype(np.float32),\n",
    "    'batterycapacity': sample_input['batterycapacity'].astype(str),\n",
    "    'bodytype': sample_input['bodytype'].astype(str),\n",
    "    'cartypename': sample_input['cartypename'].astype(str),\n",
    "    'duedateapk': sample_input['duedateapk'].astype(str),\n",
    "    'fueltype': sample_input['fueltype'].astype(str),\n",
    "    'hascosts': sample_input['hascosts'].astype(str),\n",
    "    'hascostsmanual': sample_input['hascostsmanual'].astype(str),\n",
    "    'hasdamage': sample_input['hasdamage'].astype(str),\n",
    "    'isimportcar': sample_input['isimportcar'].astype(str),\n",
    "    'modelnameshort': sample_input['modelnameshort'].astype(str),\n",
    "    'taxliabilitypercentage': sample_input['taxliabilitypercentage'].astype(str),\n",
    "    'transmissiontype': sample_input['transmissiontype'].astype(str),\n",
    "    'vatmargin': sample_input['vatmargin'].astype(str),\n",
    "    'vehicletype': sample_input['vehicletype'].astype(str)\n",
    "}\n",
    "\n",
    "# Convert the entire pipeline to ONNX\n",
    "onnx_model = to_onnx(\n",
    "    best_model,\n",
    "    X_train[:1],\n",
    "    initial_types=initial_type,\n",
    "    target_opset={\"\": 15, \"ai.onnx.ml\": 2}\n",
    ")\n",
    "\n",
    "# Save the ONNX model to a file\n",
    "with open(\"popularityModel3.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "print(\"Model has been converted to ONNX and saved as 'pipeline_lightgbm.onnx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DimitrideBoer\\OneDrive - Emixa\\Documents\\XRAYxEmixaHackathon\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2571\n",
      "[LightGBM] [Info] Number of data points in the train set: 5820, number of used features: 213\n",
      "[LightGBM] [Info] Start training from score 2.169931\n",
      "Overall Metrics:\n",
      "Mean Squared Error: 1.0808254360928276\n",
      "Mean Absolute Error: 0.7960561061347275\n",
      "R2 Score: 0.13332638841649025\n",
      "Root Mean Squared Error: 1.0396275468131977\n",
      "Model has been converted to ONNX and saved as 'pipeline_lightgbm.onnx'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from lightgbm import LGBMRegressor\n",
    "from skl2onnx import to_onnx, update_registered_converter\n",
    "from skl2onnx.common.data_types import FloatTensorType, StringTensorType\n",
    "from skl2onnx.common.shape_calculator import calculate_linear_regressor_output_shapes\n",
    "from onnxmltools.convert.lightgbm.operator_converters.LightGbm import convert_lightgbm\n",
    "import packaging.version as pv\n",
    "import onnxruntime as rt\n",
    "import warnings\n",
    "\n",
    "# Function to convert LightGBM model\n",
    "def skl2onnx_convert_lightgbm(scope, operator, container):\n",
    "    options = scope.get_options(operator.raw_operator)\n",
    "    if \"split\" in options:\n",
    "        if pv.Version(onnxmltools.__version__) < pv.Version(\"1.9.2\"):\n",
    "            warnings.warn(\n",
    "                \"Option split was released in version 1.9.2 but %s is \"\n",
    "                \"installed. It will be ignored.\" % onnxmltools.__version__\n",
    "            )\n",
    "        operator.split = options[\"split\"]\n",
    "    else:\n",
    "        operator.split = None\n",
    "    convert_lightgbm(scope, operator, container)\n",
    "\n",
    "# Register the converter for LGBMRegressor\n",
    "update_registered_converter(\n",
    "    LGBMRegressor,\n",
    "    \"LightGbmLGBMRegressor\",\n",
    "    calculate_linear_regressor_output_shapes,\n",
    "    skl2onnx_convert_lightgbm,\n",
    "    options={\"split\": None},\n",
    ")\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/PopularitySystem.csv')\n",
    "\n",
    "# Identify the columns\n",
    "target_columns = ['total_companies_bidded']\n",
    "feature_columns = df.columns.difference(target_columns).drop('total_bids')\n",
    "\n",
    "# Separate features and target variables\n",
    "X = df[feature_columns]\n",
    "y = df[target_columns]\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "numerical_cols = X.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Define the model\n",
    "model = LGBMRegressor()\n",
    "\n",
    "# Create the pipeline\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('regressor', model)])\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'regressor__num_leaves': [31],\n",
    "    'regressor__learning_rate': [0.1],\n",
    "    'regressor__n_estimators': [100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=2, scoring='neg_mean_squared_error', n_jobs=-1, verbose=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Calculate overall metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)  # Calculate RMSE\n",
    "\n",
    "print(\"Overall Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R2 Score:\", r2)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "\n",
    "# Prepare a sample input for ONNX conversion\n",
    "# Prepare a sample input for ONNX conversion\n",
    "sample_input = X_train[:1]\n",
    "\n",
    "# Convert the sample input to match the initial types\n",
    "sample_input_converted = {\n",
    "    'bpmvalue': sample_input['bpmvalue'].astype(np.float32),\n",
    "    'cardistancevalue': sample_input['cardistancevalue'].astype(np.float32),\n",
    "    'catalogincludingvalue': sample_input['catalogincludingvalue'].astype(np.float32),\n",
    "    'catalogvalue': sample_input['catalogvalue'].astype(np.float32),\n",
    "    'costsvalue': sample_input['costsvalue'].astype(np.float32),\n",
    "    'enginehorsepower': sample_input['enginehorsepower'].astype(np.float32),\n",
    "    'equipmentvalue': sample_input['equipmentvalue'].astype(np.float32),\n",
    "    'minbid': sample_input['minbid'].astype(np.float32),\n",
    "    'remainingbpmvalue': sample_input['remainingbpmvalue'].astype(np.float32),\n",
    "    'xrayvalue': sample_input['xrayvalue'].astype(np.float32),\n",
    "    'batterycapacity': sample_input['batterycapacity'].astype(str),\n",
    "    'bodytype': sample_input['bodytype'].astype(str),\n",
    "    'cartypename': sample_input['cartypename'].astype(str),\n",
    "    'duedateapk': sample_input['duedateapk'].astype(str),\n",
    "    'fueltype': sample_input['fueltype'].astype(str),\n",
    "    'hascosts': sample_input['hascosts'].astype(str),\n",
    "    'hascostsmanual': sample_input['hascostsmanual'].astype(str),\n",
    "    'hasdamage': sample_input['hasdamage'].astype(str),\n",
    "    'isimportcar': sample_input['isimportcar'].astype(str),\n",
    "    'modelnameshort': sample_input['modelnameshort'].astype(str),\n",
    "    'taxliabilitypercentage': sample_input['taxliabilitypercentage'].astype(str),\n",
    "    'transmissiontype': sample_input['transmissiontype'].astype(str),\n",
    "    'vatmargin': sample_input['vatmargin'].astype(str),\n",
    "    'vehicletype': sample_input['vehicletype'].astype(str)\n",
    "}\n",
    "\n",
    "# Convert the entire pipeline to ONNX\n",
    "onnx_model = to_onnx(\n",
    "    best_model,\n",
    "    X_train[:1],\n",
    "    target_opset={\"\": 15, \"ai.onnx.ml\": 2}\n",
    ")\n",
    "\n",
    "# Save the ONNX model to a file\n",
    "with open(\"popularityModel2.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "print(\"Model has been converted to ONNX and saved as 'pipeline_lightgbm.onnx'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
